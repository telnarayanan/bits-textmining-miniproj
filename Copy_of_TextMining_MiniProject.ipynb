{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TextMining-MiniProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLBwxcOb+L1aK/l402M8Bz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/telnarayanan/bits-textmining-miniproj/blob/main/Copy_of_TextMining_MiniProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import required libraries: \n",
        "\n",
        "\n",
        "    *   Remove Stopwords: NLTK library\n",
        "    *   Remove Special Characters: NLTK library\n",
        "    *   Convert Text to Lower Case: NLTK library\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "POP6qmLl_VJF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5CrEsmWn3mlq",
        "outputId": "eaae7ff1-3a36-4704-ef96-6f96c84f657d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'sample', 'sentence', '', 'showing', 'stop', 'words', 'filtration', '']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "  \n",
        "\n",
        "\n",
        "def filter_this_text(text_to_be_filtered):\n",
        "  # what it recives: A block of string\n",
        "  # what it returns: Filtered block of string (Tokenized, Stopwords Removed, Lower cased, punctuations removed)\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  word_tokens = word_tokenize(text_to_be_filtered)\n",
        "  filtered_sentence = []\n",
        "  for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)  \n",
        "  lower_case = [word.lower() for word in filtered_sentence]\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  stripped = [w.translate(table) for w in lower_case]\n",
        "  filtered_text = stripped\n",
        "  return(filtered_text)\n",
        "\n",
        "\n",
        "testsentence = \"\"\"This is a Sample Sentence,\n",
        "                 Showing off the stop Words Filtration.\"\"\"\n",
        "\n",
        "print(filter_this_text(testsentence))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Read the CSV File, and perform Text preprocessing operations on them\n"
      ],
      "metadata": {
        "id": "aPEIS1bUHJyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "import io\n",
        "from urllib.request import urlopen\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# https://stackoverflow.com/questions/26942476/reading-csv-zipped-files-in-python\n",
        "\n",
        "# zf = zipfile.ZipFile('https://github.com/telnarayanan/bits-textmining-miniproj/blob/main/covid-19_articles_data.csv(1).zip')\n",
        "# zf = zipfile.ZipFile('https://github.com/telnarayanan/bits-textmining-miniproj/blob/main/covid-19_articles_data.csv.zip')\n",
        "# df = pd.read_csv(zf.open('covid-19_articles_data.csv'))\n",
        "#df = pd.read_csv('https://github.com/telnarayanan/bits-textmining-miniproj/blob/main/covid-19_articles_data.csv.zip')\n",
        "#df.head(5)\n",
        "#df.tail(5)\n",
        "\n",
        "from google.colab import files\n",
        " \n",
        "\n",
        " #https://www.geeksforgeeks.org/ways-to-import-csv-files-in-google-colab/\n",
        " \n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "PV5-AT_qHUSz",
        "outputId": "04fd2c8a-7ca2-489d-b672-3e16d4df3784"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-371977a1-8708-41d1-b778-402dcfe090fd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-371977a1-8708-41d1-b778-402dcfe090fd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving covid-19_articles_data.csv to covid-19_articles_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "df = pd.read_csv(io.BytesIO(uploaded['covid-19_articles_data.csv']))\n",
        "\n",
        "print(df)\n",
        "df2 = df\n",
        "\n",
        "df3 = df2\n",
        "#df2['text']\n",
        "\n",
        "df3['text'] = df3['text'].apply(filter_this_text)\n",
        "print(df3['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qqFtEPepTVPX",
        "outputId": "6152d27a-7e78-48ec-954b-5ac8b0dc9936"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0                                               text  \\\n",
            "0               0  If you've recently heard from an old friend, y...   \n",
            "1               1  Dr. Hall says it makes sense that we would rea...   \n",
            "2               2  \"Please, if you are going to protest, take car...   \n",
            "3               3  The Tulsa Health Department sent 2 Works for Y...   \n",
            "4               4  The industry is one of the hardest hit by the ...   \n",
            "...           ...                                                ...   \n",
            "33319       33319  Ferrer again walked through data from the past...   \n",
            "33320       33320  We actually need to maintain, even more, our v...   \n",
            "33321       33321  Democrats demanded a far larger bill, includin...   \n",
            "33322       33322  RELATED: Trump says Americans can expect anoth...   \n",
            "33323       33323  2 trillion, and while Trump's negotiators have...   \n",
            "\n",
            "       sentiment  \n",
            "0              1  \n",
            "1              1  \n",
            "2              1  \n",
            "3              1  \n",
            "4              0  \n",
            "...          ...  \n",
            "33319          1  \n",
            "33320          1  \n",
            "33321          1  \n",
            "33322          1  \n",
            "33323          1  \n",
            "\n",
            "[33324 rows x 3 columns]\n",
            "0        [if, ve, recently, heard, old, friend, , re, a...\n",
            "1        [dr, hall, says, makes, sense, would, reach, p...\n",
            "2        [, please, , going, protest, , take, care, sta...\n",
            "3        [the, tulsa, health, department, sent, 2, work...\n",
            "4        [the, industry, one, hardest, hit, pandemic, ’...\n",
            "                               ...                        \n",
            "33319    [ferrer, walked, data, past, several, months, ...\n",
            "33320    [we, actually, need, maintain, , even, , vigil...\n",
            "33321    [democrats, demanded, far, larger, bill, , inc...\n",
            "33322    [related, , trump, says, americans, expect, an...\n",
            "33323    [2, trillion, , trump, s, negotiators, signale...\n",
            "Name: text, Length: 33324, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Using Train_test_split function of sklearn, split train and test dataset\n",
        "\n",
        "https://realpython.com/train-test-split-python-data/"
      ],
      "metadata": {
        "id": "gGCAARuznlKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# print(df3.shape)\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2)\n",
        "\n",
        "print(train)\n",
        "print(test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXTtvY0yQoMS",
        "outputId": "1c4c748a-0bc7-4af2-96e5-4fa236ec8620"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0                                               text  \\\n",
            "30006       30006  [it, s, played, opening, games, nfl, season, ,...   \n",
            "26683       26683  [earlier, week, , trump, slammed, fauci, gover...   \n",
            "28315       28315  [when, mommy, stressed, , get, outside, family...   \n",
            "27100       27100  [, there, s, way, parcel, carriers, equipped, ...   \n",
            "20668       20668  [on, february, 12, , locked, entire, rural, co...   \n",
            "...           ...                                                ...   \n",
            "1508         1508  [researchers, also, point, happened, uss, roos...   \n",
            "14292       14292  [the, recalled, lots, distributed, across, uni...   \n",
            "18648       18648  [designers, also, proposing, future, concepts,...   \n",
            "1540         1540  [like, approach, , covid19, , comes, vaccine, ...   \n",
            "27982       27982  [airbus, s, plan, bring, market, zeroemission,...   \n",
            "\n",
            "       sentiment  \n",
            "30006          0  \n",
            "26683          0  \n",
            "28315          0  \n",
            "27100          1  \n",
            "20668          1  \n",
            "...          ...  \n",
            "1508           0  \n",
            "14292          1  \n",
            "18648          1  \n",
            "1540           1  \n",
            "27982          1  \n",
            "\n",
            "[26659 rows x 3 columns]\n",
            "       Unnamed: 0                                               text  \\\n",
            "22739       22739  [a, tidal, wave, grief, loss, rolled, longterm...   \n",
            "1646         1646  [trump, held, two, inperson, fundraisers, earl...   \n",
            "2838         2838  [, the, last, thing, farmer, wants, euthanize,...   \n",
            "5348         5348  [, if, elections, decided, boats, rather, vote...   \n",
            "29309       29309  [shops, , bars, restaurants, must, reduce, cap...   \n",
            "...           ...                                                ...   \n",
            "19102       19102  [, i, really, affected, backlash, i, received,...   \n",
            "17992       17992  [stress, affect, quickly, food, moves, body, ,...   \n",
            "423           423  [people, likely, congregate, interact, , recon...   \n",
            "8217         8217  [”, wearing, facial, coverings, practicing, so...   \n",
            "14039       14039  [essential, devices, chastain, said, , , altho...   \n",
            "\n",
            "       sentiment  \n",
            "22739          0  \n",
            "1646           1  \n",
            "2838           1  \n",
            "5348           0  \n",
            "29309          1  \n",
            "...          ...  \n",
            "19102          1  \n",
            "17992          1  \n",
            "423            1  \n",
            "8217           1  \n",
            "14039          1  \n",
            "\n",
            "[6665 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. \n",
        "\n",
        "Create pipeline and define parameters for GridSearch ( You might Refer the code below ) - 1 Mark\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "tuned_parameters = {\n",
        "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'tfidf__norm': ('l1', 'l2'),\n",
        "    'clf__alpha': [1, 1e-1, 1e-2]\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vhWDr4VdboSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "\n",
        "tuned_parameters = {\n",
        "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'tfidf__norm': ('l1', 'l2'),\n",
        "    'clf__alpha': [1, 1e-1, 1e-2]\n",
        "}\n",
        "\n",
        "# print(tuned_parameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DNqZ0HEb4G7",
        "outputId": "0b21e5e3-8992-484c-b080-221583aad73c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'vect__ngram_range': [(1, 1), (1, 2), (2, 2)], 'tfidf__use_idf': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__alpha': [1, 0.1, 0.01]}\n"
          ]
        }
      ]
    }
  ]
}